import re
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from RealtimeSTT import AudioToTextRecorder
import os
from PIL import Image
from PIL.ExifTags import TAGS
from datetime import datetime
from deepface import DeepFace
import json
import cv2
import threading


## CACHING ##
def load_cache(cache_file="emotion_cache.json"):
    """
    Load a simple image analysis cache
    """
    if os.path.exists(cache_file):
        with open(cache_file, "r") as f:
            return json.load(f)
    return {}

def save_cache(cache, cache_file="emotion_cache.json"):
    """
    Save a simple cache"""
    with open(cache_file, "w") as f:
        json.dump(cache, f, indent=2)


## SPEECH TO TEXT ##
def extract_query_info(text):
    """
    Extract emotion category and timeframe from the user-spoken text
    """

    text = text.lower()
    analyzer = SentimentIntensityAnalyzer()
    sentiment = analyzer.polarity_scores(text)

    # Determine sentiment category of what the user said
    if sentiment['compound'] >= 0.3:
        emotion_category = "positive"
    elif sentiment['compound'] <= -0.3:
        emotion_category = "negative"
    else:
        emotion_category = "neutral"

    # Search for month
    months = [ "january", "february", "march", "april", "may", "june",
               "july", "august", "september", "october", "november", "december" ]

    # Find the month if it appears in what the user says
    found_month = next((month for month in months if month in text), None)

    # Use regex to find 4-digit year
    year_match = re.search(r"\b(20\d{2}|19\d{2})\b", text)
    found_year = int(year_match.group(1)) if year_match else None

    # Detect "top N"
    top_n = 3  # default fallback of top 3 outputs to the user
    match = re.search(r"top\s+(\d+)", text)
    if match:
        top_n = int(match.group(1))
    else:
        # Try matching number words
        for word in text.split():
            if word in {"one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten"}:
                if "top" in text:
                    top_n = word_to_number(word)
                    break

    return emotion_category, found_month, found_year, top_n

def word_to_number(word):
    """
    Converts a word numeric to an actual numberic
    """
    number_words = {
        "one": 1, "two": 2, "three": 3, "four": 4, "five": 5,
        "six": 6, "seven": 7, "eight": 8, "nine": 9, "ten": 10
    }
    return number_words.get(word.lower(), None)

## EVALUATION OF SPEECH TO TEXT
def confirm_and_evaluate_parsing(emotion_category, month, year, top_n):
    print("\nðŸ” Evaluation Time For Speech To Text:")
    print("Please confirm the following parsed values:")

    ground_truth = {}
    ground_truth['emotion'] = input(f"â†’ Was the emotion '{emotion_category}' correct? (enter 'yes' or 'no'): ").strip().lower()
    ground_truth['month'] = input(f"â†’ Was the month '{month}' correct? (enter 'yes' or 'no'): ").strip().lower()
    ground_truth['year'] = input(f"â†’ Was the year '{year}' correct? (enter 'yes' or 'no'): ").strip().lower()
    ground_truth['top_n'] = input(f"â†’ Was the top_n value '{top_n}' correct? (enter 'yes' or 'no'): ").strip().lower()

    correct = 0
    total = 4

    if ground_truth['emotion'] == "yes": correct += 1
    if ground_truth['month'] == "yes": correct += 1
    if ground_truth['year'] == "yes": correct += 1
    if ground_truth['top_n'] == "yes": correct += 1

    accuracy = (correct / total) * 100
    print(f"\nðŸ“Š Speech To Text Parsing Accuracy: {accuracy:.2f}%")
    return accuracy


## PROCESSING IMAGES ##
def get_image_date(image_path):
    """
    Extract EXIF capture date
    """
    try:
        img = Image.open(image_path)
        exif_data = img._getexif()
        if not exif_data:
            return None
        for tag_id, value in exif_data.items():
            tag = TAGS.get(tag_id, tag_id)
            if tag == "DateTimeOriginal":
                return datetime.strptime(value, '%Y:%m:%d %H:%M:%S')
    except Exception as e:
        print(f"âš ï¸ Could not get date from {image_path}: {e}")
    return None

def filter_images_by_date(folder, target_month, target_year):
    """
    Filter images by month and year
    """
    matching_images = []
    for fname in os.listdir(folder):
        if not fname.lower().endswith((".jpg", ".jpeg", ".png")):
            continue

        path = os.path.join(folder, fname)
        date = get_image_date(path)
        if date:
            if (date.strftime('%B').lower() == target_month.lower() and date.year == target_year):
                matching_images.append(path)
        else:
            # If not date was found for the image, we will consider it part of what could be returned to user
            matching_images.append(path)

    return matching_images

## EMOTION DETECTION ##

# Map DeepFace emotions to high-level sentiment categories
emotion_map = {
    "happy": "positive",
    "surprise": "positive",
    "neutral": "neutral",
    "sad": "negative",
    "angry": "negative",
    "fear": "negative",
    "disgust": "negative"
}

def filter_images_by_emotion(image_paths, desired_category, top_n=3):
    """
    Detecting dominant emotion in images and collecting top n matching images
    """
    cache = load_cache()

    scored_images = []

    for path in image_paths:
        print(f"ðŸ–¼ï¸ Analyzing: {os.path.basename(path)}")
        path_key = os.path.abspath(path)
        try:
            if path_key in cache:
                result = cache[path_key]
                print("   â†ª Using cached result")
            else:
                result = DeepFace.analyze(img_path=path, actions=["emotion"], enforce_detection=False)
                cache[path_key] = result


            emotion_scores = result[0]["emotion"]  # dictionary of emotion: score
            dominant_emotion = result[0]["dominant_emotion"].lower()

            # Get overall sentiment category of dominant emotion
            mapped_category = emotion_map.get(dominant_emotion, "neutral")

            if mapped_category == desired_category:
                # Score = confidence in the matching emotion category
                relevant_emotions = [k for k, v in emotion_map.items() if v == desired_category]
                strength_score = sum(emotion_scores.get(e, 0) for e in relevant_emotions)

                scored_images.append({
                    "path": path,
                    "dominant": dominant_emotion,
                    "score": strength_score
                })

                print(f"   â†’ Detected: {dominant_emotion} | Score: {strength_score:.2f}")

        except Exception as e:
            print(f"   âŒ Error analyzing {path}: {e}")

    save_cache(cache)

    # Sort images by strength score (descending)
    top_images = sorted(scored_images, key=lambda x: x["score"], reverse=True)

    return top_images[:top_n]

## PROCESSING LOGIC FLOW ##

# EVALUATION FOR IMAGE RETRIEVAL SENTIMENT MATCHES #
def show_images_with_feedback(image_results, expected_emotion):
    correct = 0
    for r in image_results:
        img = cv2.imread(r["path"])

        fixed_width = 800
        height, width = img.shape[:2]
        scale = fixed_width / width
        new_dims = (fixed_width, int(height * scale))
        img = cv2.resize(img, new_dims)

        label = f"{os.path.basename(r['path'])} ({r['dominant']} - {r['score']:.2f})"
        cv2.imshow(label, img)
        cv2.waitKey(0)
        cv2.destroyAllWindows()

        feedback = input(f"âœ… Does this image match '{expected_emotion}' sentiment? (yes/no): ").strip().lower()
        if feedback == "yes":
            correct += 1

    accuracy = (correct / len(image_results)) * 100 if image_results else 0
    print(f"\nðŸ§ª Emotion Matching Photos Retrieval Accuracy: {accuracy:.2f}%")
    return accuracy

def process_logic(text):
    """
    Wrapper logic function to manage the flow and provide feedback to the user
    """
    print("\nðŸ“ You said:", text)

    emotion_category, month, year, top_n = extract_query_info(text)

    # Show results to the user
    match emotion_category:
        case "positive":
            print("ðŸ˜„ Sentiment detected: POSITIVE (happy, joyful, etc.)")
        case "negative":
            print("ðŸ˜ž Sentiment detected: NEGATIVE (sad, angry, etc.)")
        case _:
            print("ðŸ˜ Sentiment detected: NEUTRAL")

    if month and year:
        print(f"ðŸ“† Timeframe detected: {month.title()} {year}")
    elif month:
        print(f"ðŸ“† Month detected: {month.title()} (year missing)")
    elif year:
        print(f"ðŸ“† Year detected: {year} (month missing)")
    else:
        print("ðŸ“† No clear date found.")

    print(f"ðŸ† Top {top_n} results requested")

    confirm_and_evaluate_parsing(emotion_category, month, year, top_n)

    print("\nâœ… Ready to search for matching photos based on sentiment and timeframe...\n")

    folder = "images"
    filtered_images = filter_images_by_date(folder, month, year)

    print(f"\nðŸ“‚ Found {len(filtered_images)} images from {month.title()} {year}:")
    for f in filtered_images:
        print(" -", f)

    top_emotion_results = filter_images_by_emotion(filtered_images, emotion_category, top_n)

    print(f"\nâœ… Top {top_n} {emotion_category} images:")
    for r in top_emotion_results:
        print(f" - {r['path']} (Score: {r['score']:.2f}, Emotion: {r['dominant']})")

    if top_emotion_results:
        print("\nðŸ–¼ï¸ Displaying top results...")
        show_images_with_feedback(top_emotion_results, emotion_category)
    else:
        print("âš ï¸ No matching images to display.")

if __name__ == '__main__':
    print("ðŸŽ‰ Welcome to SentimentSearch!")
    print("ðŸŽ¤ Please wait for the prompt, then speak your query.")
    print("ðŸ’¬ Try something like: 'Show me the top 4 not negative pictures from February of 2025'\n")

    recorder = AudioToTextRecorder()

    while True:
        done_event = threading.Event()

        def wrapped_process_logic(text):
            process_logic(text)
            done_event.set()

        # Wait Until The Logic Has Been Processed Before Asking The User For Potentially Another Query
        recorder.text(wrapped_process_logic)
        done_event.wait()

        cont = input("\nðŸ” Do you want to try another query? (yes/no): ").strip().lower()
        if cont not in ["yes", "y"]:
            print("ðŸ‘‹ Goodbye! Thanks for using SentimentSearch.")
            break
